{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiBPfVszEA6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11a91632-de71-48f7-9934-42de369124fa"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import convolutional,pooling,Dense,Flatten,BatchNormalization,Reshape,Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6jAUP7qEGF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d1afadd-f340-4c18-9429-7102e3483ea7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2chMdU9HDd4",
        "colab_type": "text"
      },
      "source": [
        "Getting the data and resizing the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRMBJU7KUrV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_path =  '/content/drive/My Drive/PGAIML/CNN/Project1/plant_seed_classification/train/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkryukbpNdIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liQY1TRNlYBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = {'Black-grass':0,'Charlock':1,'Cleavers':2,'Common Chickweed':3,'Common wheat':4,'Fat Hen':5,'Loose Silky-bent':6,'Maize':7,\n",
        "           'Scentless Mayweed':8,'Shepherds Purse':9,'Small-flowered Cranesbill':10,'Sugar beet':11}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0fvZC9KmWwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_count = 0\n",
        "tot_img_count = 0\n",
        "class_count = 0\n",
        "for every_class in classes.keys():\n",
        "  every_collection = skimage.io.imread_collection(image_path+every_class+'/*.png',conserve_memory=True)\n",
        "  class_count+=1 \n",
        "  for every_image in every_collection:\n",
        "    img_count+=1\n",
        "    img = skimage.transform.resize(image = every_image,output_shape=(image_size,image_size))\n",
        "    \n",
        "    if(img_count==1):\n",
        "      x_train_every_image = img[:,:,:3]\n",
        "    else:\n",
        "      x_train_every_image = np.vstack((x_train_every_image,img[:,:,:3]))\n",
        "    \n",
        "  y = classes[every_class]*np.ones(shape=(len(every_collection.files),),dtype='int32')\n",
        "  if(class_count==1):\n",
        "    x_train = x_train_every_image\n",
        "    y_train=y\n",
        "  else:\n",
        "    y_train=np.concatenate((y_train,y))\n",
        "    x_train = np.vstack((x_train,x_train_every_image))\n",
        "  \n",
        "  \n",
        "  tot_img_count +=img_count\n",
        "  img_count=0\n",
        "\n",
        "x_train=x_train.reshape(tot_img_count,image_size,image_size,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG8jl26Oriog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8be6e593-cd0b-420d-daf0-d6072c62f191"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4750, 128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHLk8RC_fzjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75076a2c-d99f-4628-83b2-e4205073a6e5"
      },
      "source": [
        "class_count"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQqGQoe4f2px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y=y_train,num_classes=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8TK2EzNf9lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_training,x_validate,y_training,y_validate = train_test_split(x_train,y_train,test_size=0.2,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbf3yqS5n5xU",
        "colab_type": "text"
      },
      "source": [
        "# Set the CNN model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNymNTGBgD83",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "3c171321-dd57-47a2-f56c-76262e77a525"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.layers import Conv2D, MaxPool2D, GlobalMaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "model = Sequential()\n",
        "model.add(convolutional.Conv2D(input_shape=(128,128,3),filters=20,kernel_size=4,strides=4,data_format='channels_last',activation='relu'))\n",
        "model.add(convolutional.Conv2D(input_shape=(20,32,32,3),filters=20,kernel_size=3,strides=2,data_format='channels_last',activation='relu'))\n",
        "model.add(convolutional.Conv2D(input_shape=(20,15,15,3),filters=20,kernel_size=3,strides=1,data_format='channels_last',activation='relu'))\n",
        "\n",
        "model.add(pooling.AvgPool2D(pool_size=3,strides=2,data_format='channels_last',input_shape=(20,15,15,3)))\n",
        "model.add(pooling.AvgPool2D(pool_size=3,strides=1,data_format='channels_last',input_shape=(20,7,7,3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=3940,activation='relu',input_shape=()))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=600,activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=50,activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(units=12,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 20)        980       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 20)        3620      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 20)        3620      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 6, 6, 20)          0         \n",
            "_________________________________________________________________\n",
            "average_pooling2d_2 (Average (None, 4, 4, 20)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3940)              1264740   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3940)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 3940)              15760     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 600)               2364600   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 600)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 600)               2400      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 50)                30050     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 12)                612       \n",
            "=================================================================\n",
            "Total params: 3,686,582\n",
            "Trainable params: 3,677,402\n",
            "Non-trainable params: 9,180\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mecdkPipAIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f07358b4-6dd8-4c1d-da3b-0e2138388fe4"
      },
      "source": [
        "\n",
        "opt = Adam(lr=0.001)\n",
        "\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "model.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DUNVWfcpL2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69393e0c-fc31-4c22-b6a4-7aab1f02b17f"
      },
      "source": [
        "model.fit(x_training, y_training, epochs = 90, validation_data = (x_validate,y_validate),batch_size = 32)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 3800 samples, validate on 950 samples\n",
            "Epoch 1/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.2080 - acc: 0.9266 - val_loss: 0.4303 - val_acc: 0.8821\n",
            "Epoch 2/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.2064 - acc: 0.9268 - val_loss: 0.4219 - val_acc: 0.8758\n",
            "Epoch 3/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.2061 - acc: 0.9250 - val_loss: 0.5768 - val_acc: 0.8537\n",
            "Epoch 4/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.2018 - acc: 0.9284 - val_loss: 0.4298 - val_acc: 0.8642\n",
            "Epoch 5/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1931 - acc: 0.9308 - val_loss: 0.6186 - val_acc: 0.8505\n",
            "Epoch 6/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1889 - acc: 0.9271 - val_loss: 0.7506 - val_acc: 0.8326\n",
            "Epoch 7/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1785 - acc: 0.9345 - val_loss: 1.1124 - val_acc: 0.7537\n",
            "Epoch 8/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1818 - acc: 0.9387 - val_loss: 0.9010 - val_acc: 0.7968\n",
            "Epoch 9/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1816 - acc: 0.9350 - val_loss: 0.3960 - val_acc: 0.8916\n",
            "Epoch 10/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1828 - acc: 0.9368 - val_loss: 0.4843 - val_acc: 0.8621\n",
            "Epoch 11/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1895 - acc: 0.9321 - val_loss: 0.3803 - val_acc: 0.8684\n",
            "Epoch 12/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1595 - acc: 0.9445 - val_loss: 0.6807 - val_acc: 0.8474\n",
            "Epoch 13/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1628 - acc: 0.9432 - val_loss: 0.4044 - val_acc: 0.8821\n",
            "Epoch 14/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1582 - acc: 0.9411 - val_loss: 0.4908 - val_acc: 0.8663\n",
            "Epoch 15/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1629 - acc: 0.9413 - val_loss: 0.4341 - val_acc: 0.8884\n",
            "Epoch 16/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1700 - acc: 0.9442 - val_loss: 0.5607 - val_acc: 0.8674\n",
            "Epoch 17/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1532 - acc: 0.9455 - val_loss: 0.4297 - val_acc: 0.8768\n",
            "Epoch 18/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1741 - acc: 0.9411 - val_loss: 0.4545 - val_acc: 0.8842\n",
            "Epoch 19/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1653 - acc: 0.9403 - val_loss: 0.9384 - val_acc: 0.7684\n",
            "Epoch 20/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1552 - acc: 0.9484 - val_loss: 0.3526 - val_acc: 0.9000\n",
            "Epoch 21/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1480 - acc: 0.9461 - val_loss: 0.6107 - val_acc: 0.8179\n",
            "Epoch 22/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1605 - acc: 0.9445 - val_loss: 0.4099 - val_acc: 0.8916\n",
            "Epoch 23/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1515 - acc: 0.9489 - val_loss: 0.9379 - val_acc: 0.7853\n",
            "Epoch 24/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1520 - acc: 0.9487 - val_loss: 0.4570 - val_acc: 0.8726\n",
            "Epoch 25/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1389 - acc: 0.9508 - val_loss: 0.4179 - val_acc: 0.8579\n",
            "Epoch 26/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1341 - acc: 0.9545 - val_loss: 1.2568 - val_acc: 0.7316\n",
            "Epoch 27/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1527 - acc: 0.9537 - val_loss: 0.8324 - val_acc: 0.7979\n",
            "Epoch 28/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1353 - acc: 0.9539 - val_loss: 0.6244 - val_acc: 0.8589\n",
            "Epoch 29/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1455 - acc: 0.9489 - val_loss: 0.4274 - val_acc: 0.8884\n",
            "Epoch 30/90\n",
            "3800/3800 [==============================] - 9s 2ms/step - loss: 0.1318 - acc: 0.9582 - val_loss: 0.7703 - val_acc: 0.8168\n",
            "Epoch 31/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1485 - acc: 0.9511 - val_loss: 0.7972 - val_acc: 0.8137\n",
            "Epoch 32/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1343 - acc: 0.9571 - val_loss: 0.7532 - val_acc: 0.8242\n",
            "Epoch 33/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1252 - acc: 0.9589 - val_loss: 0.6825 - val_acc: 0.8474\n",
            "Epoch 34/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1170 - acc: 0.9621 - val_loss: 0.4722 - val_acc: 0.8937\n",
            "Epoch 35/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1319 - acc: 0.9558 - val_loss: 0.7392 - val_acc: 0.8526\n",
            "Epoch 36/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1275 - acc: 0.9597 - val_loss: 0.6301 - val_acc: 0.8589\n",
            "Epoch 37/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1453 - acc: 0.9503 - val_loss: 0.4629 - val_acc: 0.9042\n",
            "Epoch 38/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1283 - acc: 0.9613 - val_loss: 0.7772 - val_acc: 0.8116\n",
            "Epoch 39/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1186 - acc: 0.9629 - val_loss: 0.4665 - val_acc: 0.8905\n",
            "Epoch 40/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1118 - acc: 0.9650 - val_loss: 0.7043 - val_acc: 0.8558\n",
            "Epoch 41/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1094 - acc: 0.9632 - val_loss: 0.5298 - val_acc: 0.8747\n",
            "Epoch 42/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1152 - acc: 0.9634 - val_loss: 0.6821 - val_acc: 0.8537\n",
            "Epoch 43/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1236 - acc: 0.9605 - val_loss: 0.8118 - val_acc: 0.8274\n",
            "Epoch 44/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1132 - acc: 0.9663 - val_loss: 0.5898 - val_acc: 0.8653\n",
            "Epoch 45/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1035 - acc: 0.9661 - val_loss: 0.4867 - val_acc: 0.8926\n",
            "Epoch 46/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1131 - acc: 0.9618 - val_loss: 0.8096 - val_acc: 0.8484\n",
            "Epoch 47/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1136 - acc: 0.9600 - val_loss: 0.4859 - val_acc: 0.8905\n",
            "Epoch 48/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1016 - acc: 0.9682 - val_loss: 1.0416 - val_acc: 0.7579\n",
            "Epoch 49/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1056 - acc: 0.9676 - val_loss: 0.4564 - val_acc: 0.8874\n",
            "Epoch 50/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0940 - acc: 0.9676 - val_loss: 0.6195 - val_acc: 0.8516\n",
            "Epoch 51/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1103 - acc: 0.9658 - val_loss: 0.8435 - val_acc: 0.8274\n",
            "Epoch 52/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1063 - acc: 0.9634 - val_loss: 0.5674 - val_acc: 0.8726\n",
            "Epoch 53/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1136 - acc: 0.9634 - val_loss: 0.5876 - val_acc: 0.8747\n",
            "Epoch 54/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0872 - acc: 0.9711 - val_loss: 0.7082 - val_acc: 0.8558\n",
            "Epoch 55/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0993 - acc: 0.9658 - val_loss: 0.8458 - val_acc: 0.8074\n",
            "Epoch 56/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0928 - acc: 0.9705 - val_loss: 0.5465 - val_acc: 0.8695\n",
            "Epoch 57/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0998 - acc: 0.9676 - val_loss: 0.7939 - val_acc: 0.8284\n",
            "Epoch 58/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0901 - acc: 0.9726 - val_loss: 0.9715 - val_acc: 0.8074\n",
            "Epoch 59/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1080 - acc: 0.9650 - val_loss: 0.5001 - val_acc: 0.8853\n",
            "Epoch 60/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1151 - acc: 0.9658 - val_loss: 0.5045 - val_acc: 0.8989\n",
            "Epoch 61/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0892 - acc: 0.9724 - val_loss: 0.6678 - val_acc: 0.8589\n",
            "Epoch 62/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0772 - acc: 0.9734 - val_loss: 0.5568 - val_acc: 0.8653\n",
            "Epoch 63/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0871 - acc: 0.9726 - val_loss: 0.8682 - val_acc: 0.8116\n",
            "Epoch 64/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0934 - acc: 0.9708 - val_loss: 0.5365 - val_acc: 0.8905\n",
            "Epoch 65/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0962 - acc: 0.9671 - val_loss: 0.4943 - val_acc: 0.8905\n",
            "Epoch 66/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0894 - acc: 0.9726 - val_loss: 0.5274 - val_acc: 0.8768\n",
            "Epoch 67/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0917 - acc: 0.9684 - val_loss: 0.5172 - val_acc: 0.8779\n",
            "Epoch 68/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.1014 - acc: 0.9692 - val_loss: 0.5819 - val_acc: 0.8747\n",
            "Epoch 69/90\n",
            "3800/3800 [==============================] - 9s 2ms/step - loss: 0.1000 - acc: 0.9697 - val_loss: 0.6892 - val_acc: 0.8389\n",
            "Epoch 70/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0856 - acc: 0.9724 - val_loss: 0.5172 - val_acc: 0.8695\n",
            "Epoch 71/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0812 - acc: 0.9716 - val_loss: 0.4683 - val_acc: 0.8958\n",
            "Epoch 72/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0838 - acc: 0.9734 - val_loss: 0.7613 - val_acc: 0.8358\n",
            "Epoch 73/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0906 - acc: 0.9737 - val_loss: 0.6785 - val_acc: 0.8526\n",
            "Epoch 74/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0929 - acc: 0.9687 - val_loss: 0.7417 - val_acc: 0.8358\n",
            "Epoch 75/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0836 - acc: 0.9718 - val_loss: 0.7150 - val_acc: 0.8547\n",
            "Epoch 76/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0818 - acc: 0.9726 - val_loss: 0.6820 - val_acc: 0.8568\n",
            "Epoch 77/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0877 - acc: 0.9729 - val_loss: 0.7714 - val_acc: 0.8600\n",
            "Epoch 78/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0848 - acc: 0.9705 - val_loss: 0.7100 - val_acc: 0.8705\n",
            "Epoch 79/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0667 - acc: 0.9766 - val_loss: 0.5497 - val_acc: 0.8779\n",
            "Epoch 80/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0764 - acc: 0.9758 - val_loss: 0.5236 - val_acc: 0.8705\n",
            "Epoch 81/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0749 - acc: 0.9726 - val_loss: 0.7966 - val_acc: 0.8537\n",
            "Epoch 82/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0930 - acc: 0.9697 - val_loss: 0.5519 - val_acc: 0.8916\n",
            "Epoch 83/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0706 - acc: 0.9779 - val_loss: 0.5149 - val_acc: 0.8958\n",
            "Epoch 84/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0763 - acc: 0.9737 - val_loss: 0.6780 - val_acc: 0.8526\n",
            "Epoch 85/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0690 - acc: 0.9771 - val_loss: 0.5942 - val_acc: 0.8884\n",
            "Epoch 86/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0935 - acc: 0.9737 - val_loss: 0.8222 - val_acc: 0.8663\n",
            "Epoch 87/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0780 - acc: 0.9737 - val_loss: 0.8325 - val_acc: 0.8326\n",
            "Epoch 88/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0815 - acc: 0.9763 - val_loss: 1.1028 - val_acc: 0.7937\n",
            "Epoch 89/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0852 - acc: 0.9726 - val_loss: 0.6569 - val_acc: 0.8779\n",
            "Epoch 90/90\n",
            "3800/3800 [==============================] - 8s 2ms/step - loss: 0.0722 - acc: 0.9758 - val_loss: 0.5710 - val_acc: 0.8811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ec9d02828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecl0o-S0tmrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('model_cnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnHRQiasBhy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('model_cnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8sFGYvxBk5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fd45133-2f7c-4921-9983-b4112bc6daf4"
      },
      "source": [
        "loss, acc = model.evaluate(x_validate,  y_validate, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restored model, accuracy: 88.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAPpoLcWDbQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}